{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d2838e",
   "metadata": {},
   "source": [
    "# Grad-CAM Explainability\n",
    "\n",
    "This notebook loads the trained EfficientNetB3 plant disease model and uses Grad-CAM to visualize **which regions of a plant image the model focuses on** when making a prediction.\n",
    "\n",
    "You can:\n",
    "- Pick a test image\n",
    "- See prediction + Grad-CAM heatmap + overlay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82777fe",
   "metadata": {},
   "source": [
    "# 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e5e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in d:\\anaconda\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.12.0\n",
      "4.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b26bf",
   "metadata": {},
   "source": [
    "# 2. Model path and class names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699087fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"Models/EfficientNetB3/efficientnetb3_model.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6f104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names \n",
    "CLASS_NAMES = [\n",
    "    'Pepper__bell___Bacterial_spot',\n",
    "    'Pepper__bell___healthy',\n",
    "    'Potato___Early_blight',\n",
    "    'Potato___Late_blight',\n",
    "    'Potato___healthy',\n",
    "    'Tomato__Target_Spot',\n",
    "    'Tomato__Tomato_YellowLeaf__Curl_Virus',\n",
    "    'Tomato__Tomato_mosaic_virus',\n",
    "    'Tomato_healthy'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f37cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: Models/EfficientNetB3/efficientnetb3_model.keras\n",
      "Model file exists: True\n",
      "Num classes: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Model path:\", MODEL_PATH)\n",
    "print(\"Model file exists:\", os.path.exists(MODEL_PATH))\n",
    "print(\"Num classes:\", len(CLASS_NAMES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9b19e",
   "metadata": {},
   "source": [
    "## 3. Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51dc6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Model output shape: (None, 9)\n",
      "\n",
      "Model layers:\n",
      "  0: efficientnetb3 - Functional\n",
      "      Output shape: (None, 7, 7, 1536)\n",
      "  1: global_average_pooling2d - GlobalAveragePooling2D\n",
      "  2: dropout - Dropout\n",
      "  3: dense - Dense\n",
      "  4: dropout_1 - Dropout\n",
      "  5: dense_1 - Dense\n",
      "\n",
      "✓ Found base model: efficientnetb3\n",
      "  Base model output shape: (None, 7, 7, 1536)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(MODEL_PATH)\n",
    "print(\"Model loaded successfully!\")\n",
    "print(\"Model output shape:\", model.output_shape)\n",
    "\n",
    "# Print model structure for verification\n",
    "print(\"\\nModel layers:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"  {i}: {layer.name} - {type(layer).__name__}\")\n",
    "    if hasattr(layer, 'output_shape'):\n",
    "        print(f\"      Output shape: {layer.output_shape}\")\n",
    "\n",
    "# Verify base model exists\n",
    "base_model_found = False\n",
    "for layer in model.layers:\n",
    "    if 'efficientnet' in layer.name.lower():\n",
    "        base_model_found = True\n",
    "        print(f\"\\n✓ Found base model: {layer.name}\")\n",
    "        print(f\"  Base model output shape: {layer.output_shape}\")\n",
    "        break\n",
    "\n",
    "if not base_model_found:\n",
    "    print(\"\\n Warning: Could not find EfficientNetB3 base model in the expected location.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf626913",
   "metadata": {},
   "source": [
    "## 4. Verify model is ready for Grad-CAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491be57b",
   "metadata": {},
   "source": [
    "### Ensure model can compute gradients\n",
    "### For EfficientNet, we'll verify the model structure is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying model structure for Grad-CAM...\n",
      "✓ Base model found: efficientnetb3\n",
      "  Output shape: (None, 7, 7, 1536)\n",
      " Error during verification: The layer sequential has never been called and thus has no defined output.\n",
      "  The model may still work, but there might be issues.\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying model structure for Grad-CAM...\")\n",
    "try:\n",
    "    # Check if we can access the base model\n",
    "    base_model = None\n",
    "    for layer in model.layers:\n",
    "        if 'efficientnet' in layer.name.lower():\n",
    "            base_model = layer\n",
    "            break\n",
    "    \n",
    "    if base_model:\n",
    "        print(f\"✓ Base model found: {base_model.name}\")\n",
    "        print(f\"  Output shape: {base_model.output_shape}\")\n",
    "        \n",
    "        # Test that we can build a grad model\n",
    "        test_grad_model = keras.models.Model(\n",
    "            [model.inputs],\n",
    "            [base_model.output, model.output]\n",
    "        )\n",
    "        print(\"✓ Grad model can be built successfully\")\n",
    "        \n",
    "        # Test with a dummy input\n",
    "        dummy_input = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "        test_output = test_grad_model(dummy_input)\n",
    "        print(f\"✓ Test forward pass successful\")\n",
    "        print(f\"  Conv output shape: {test_output[0].shape}\")\n",
    "        print(f\"  Prediction output shape: {test_output[1].shape}\")\n",
    "        print(\"\\n✓ Model is ready for Grad-CAM!\")\n",
    "    else:\n",
    "        print(\" Could not find base model - Grad-CAM may not work correctly\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Error during verification: {e}\")\n",
    "    print(\"  The model may still work, but there might be issues.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533774d",
   "metadata": {},
   "source": [
    "## 5. Image loading & preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_resized = img.resize(IMG_SIZE)\n",
    "    img_array = np.array(img_resized).astype(\"float32\") / 255.0\n",
    "    img_batch = np.expand_dims(img_array, axis=0)  # (1, 224, 224, 3)\n",
    "    return img, img_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a84514",
   "metadata": {},
   "source": [
    "# 6. Grad-CAM core function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7554aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Grad-CAM function loaded\n"
     ]
    }
   ],
   "source": [
    "def gradcam_heatmap(img_array, model, last_conv_layer_name=None):\n",
    "\n",
    "    # 1. Find last conv layer if not specified\n",
    "    if last_conv_layer_name is None:\n",
    "        # Find the EfficientNetB3 base model\n",
    "        base_model = None\n",
    "        for layer in model.layers:\n",
    "            if 'efficientnet' in layer.name.lower() or (hasattr(layer, \"layers\") and len(layer.layers) > 50):\n",
    "                base_model = layer\n",
    "                break\n",
    "        \n",
    "        if base_model is None:\n",
    "            raise ValueError(\n",
    "                \"Could not find EfficientNetB3 base model in the model structure.\\n\"\n",
    "                \"Available layers: \" + \", \".join([l.name for l in model.layers])\n",
    "            )\n",
    "        \n",
    "        last_conv_layer_name = base_model.name\n",
    "        use_base_output = True\n",
    "        print(f\"Using base model '{last_conv_layer_name}' output for Grad-CAM\")\n",
    "    else:\n",
    "        use_base_output = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 2. Build a model where predictions actually use the base_output we extract\n",
    "\n",
    "    input_shape = model.input_shape[1:] if hasattr(model, 'input_shape') and model.input_shape else (224, 224, 3)\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    base_model_layer = model.get_layer(last_conv_layer_name)\n",
    "\n",
    "    # Get base model output - this is what we want gradients for\n",
    "    base_output = base_model_layer(input_layer)\n",
    "    \n",
    "    # Get the layers after the base model\n",
    "    x = base_output\n",
    "    base_model_index = None\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if layer.name == last_conv_layer_name:\n",
    "            base_model_index = i\n",
    "            break\n",
    "    \n",
    "    if base_model_index is not None:\n",
    "        # Apply all layers after the base model\n",
    "        for i in range(base_model_index + 1, len(model.layers)):\n",
    "            x = model.layers[i](x)\n",
    "        full_output = x\n",
    "    else:\n",
    "        full_output = model(input_layer)\n",
    "    \n",
    "    grad_model = keras.models.Model(inputs=input_layer, outputs=[base_output, full_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 3. Temporarily enable gradient computation for all layers\n",
    "    # Save original trainable states\n",
    "    original_trainable_states = {}\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'trainable'):\n",
    "            original_trainable_states[layer] = layer.trainable\n",
    "            layer.trainable = True\n",
    "        # check nested layers \n",
    "        if hasattr(layer, 'layers'):\n",
    "            for sublayer in layer.layers:\n",
    "                if hasattr(sublayer, 'trainable'):\n",
    "                    original_trainable_states[sublayer] = sublayer.trainable\n",
    "                    sublayer.trainable = True\n",
    "    \n",
    "    # Convert to tensor if needed\n",
    "    if not isinstance(img_array, tf.Tensor):\n",
    "        img_array = tf.constant(img_array, dtype=tf.float32)\n",
    "    \n",
    "    # Enable gradient computation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute both outputs \n",
    "        conv_outputs, predictions = grad_model(img_array, training=True)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        pred_score = predictions[:, pred_index]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 4. Compute gradients\n",
    "\n",
    "    grads = tape.gradient(pred_score, conv_outputs)\n",
    "    \n",
    "    # Restore original trainable states\n",
    "    for layer, trainable_state in original_trainable_states.items():\n",
    "        layer.trainable = trainable_state\n",
    "    \n",
    "    if grads is None:\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            # Get base model output\n",
    "            base_out = base_model_layer(img_array, training=True)\n",
    "            # Get prediction\n",
    "            pred = model(img_array, training=True)\n",
    "            pred_idx = tf.argmax(pred[0])\n",
    "            pred_sc = pred[:, pred_idx]\n",
    "        \n",
    "        # get gradient of prediction w.r.t. base output\n",
    "        grads = tape2.gradient(pred_sc, base_out)\n",
    "        del tape2\n",
    "        \n",
    "        if grads is None:\n",
    "            raise ValueError(\n",
    "                \"Unable to compute gradients. The model architecture may not support Grad-CAM.\\n\"\n",
    "                \"Try ensuring the model was saved with the correct structure.\"\n",
    "            )\n",
    "        \n",
    "        # By the base output \n",
    "        conv_outputs = base_out\n",
    "        predictions = pred\n",
    "        pred_index = pred_idx\n",
    "        pred_score = pred_sc\n",
    "    \n",
    "    # Handle batch dimension\n",
    "    if len(grads.shape) == 4: \n",
    "        grads = grads[0]   \n",
    "    if len(conv_outputs.shape) == 4: \n",
    "        conv_outputs = conv_outputs[0]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 5. Global-average-pool the gradients over spatial dims\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))         # (C,)\n",
    "\n",
    "    # 6. Weighted sum of feature maps\n",
    "    cam = tf.tensordot(conv_outputs, weights, axes=(2, 0))  # (H, W)\n",
    "    cam = np.maximum(cam, 0)  # ReLU\n",
    "    cam /= (cam.max() + 1e-8)  # Normalize\n",
    "\n",
    "    # Convert to numpy if it's a tensor, otherwise it's already numpy\n",
    "    if hasattr(cam, 'numpy'):\n",
    "        cam = cam.numpy()\n",
    "    elif isinstance(cam, tf.Tensor):\n",
    "        cam = cam.numpy()\n",
    "    \n",
    "    # Convert predictions to numpy if needed\n",
    "    if hasattr(predictions, 'numpy'):\n",
    "        pred_value = float(predictions[0, pred_index].numpy())\n",
    "    elif isinstance(predictions, tf.Tensor):\n",
    "        pred_value = float(predictions[0, pred_index].numpy())\n",
    "    else:\n",
    "        pred_value = float(predictions[0, pred_index])\n",
    "    \n",
    "    return cam, int(pred_index), pred_value\n",
    "\n",
    "\n",
    "print(\"  Grad-CAM function loaded\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7743c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
