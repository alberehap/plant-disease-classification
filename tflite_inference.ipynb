{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560f8f64",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c1018",
   "metadata": {},
   "source": [
    "### flatifying images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cde58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied images to: flat_test_images/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Create a flat test folder\n",
    "flat_test_folder = \"flat_test_images/\"\n",
    "os.makedirs(flat_test_folder, exist_ok=True)\n",
    "\n",
    "# Copy all images from processed/test to flat folder\n",
    "source_folder = \"data/processed/test/\"\n",
    "for root, dirs, files in os.walk(source_folder):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            src_path = os.path.join(root, file)\n",
    "            # Create unique filename with class name\n",
    "            class_name = os.path.basename(root)\n",
    "            new_filename = f\"{class_name}_{file}\"\n",
    "            dst_path = os.path.join(flat_test_folder, new_filename)\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(f\"Copied images to: {flat_test_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50022d08",
   "metadata": {},
   "source": [
    "## INFERENCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c970639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plant_detector.py - Core Detection Engine\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class PlantDiseaseDetector:\n",
    "    \n",
    "    CLASS_NAMES = [\n",
    "        'Pepper__bell___Bacterial_spot',\n",
    "        'Pepper__bell___healthy', \n",
    "        'Potato___Early_blight',\n",
    "        'Potato___Late_blight',\n",
    "        'Potato___healthy',\n",
    "        'Tomato__Target_Spot',\n",
    "        'Tomato__Tomato_YellowLeaf__Curl_Virus',\n",
    "        'Tomato__Tomato_mosaic_virus',\n",
    "        'Tomato_healthy'\n",
    "    ]\n",
    "    \n",
    "    # User-friendly names\n",
    "    FRIENDLY_NAMES = {\n",
    "        'Pepper__bell___Bacterial_spot': 'Pepper - Bacterial Spot',\n",
    "        'Pepper__bell___healthy': 'Pepper - Healthy',\n",
    "        'Potato___Early_blight': 'Potato - Early Blight',\n",
    "        'Potato___Late_blight': 'Potato - Late Blight',\n",
    "        'Potato___healthy': 'Potato - Healthy',\n",
    "        'Tomato__Target_Spot': 'Tomato - Target Spot',\n",
    "        'Tomato__Tomato_YellowLeaf__Curl_Virus': 'Tomato - Yellow Leaf Curl Virus',\n",
    "        'Tomato__Tomato_mosaic_virus': 'Tomato - Mosaic Virus',\n",
    "        'Tomato_healthy': 'Tomato - Healthy'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, model_path=\"Models/tflite_conversion/best_model.tflite\"):\n",
    "        self.model = self._load_model(model_path)\n",
    "        \n",
    "    def _load_model(self, model_path):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        print(f\"Model loaded: {model_path}\")\n",
    "        return self.interpreter\n",
    "    \n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "  \n",
    "        # Handle different input types\n",
    "        if isinstance(image, str):  # File path\n",
    "            img = cv2.imread(image)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Could not read image from path: {image}\")\n",
    "        elif isinstance(image, bytes):  # Bytes\n",
    "            nparr = np.frombuffer(image, np.uint8)\n",
    "            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "            if img is None:\n",
    "                raise ValueError(\"Could not decode image from bytes\")\n",
    "        elif hasattr(image, 'convert'):  # PIL Image\n",
    "            img = np.array(image.convert('RGB'))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        elif isinstance(image, np.ndarray):  # numpy array\n",
    "            img = image.copy()\n",
    "            # Convert RGBA to RGB if needed\n",
    "            if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)\n",
    "            # Assume RGB, convert to BGR for OpenCV\n",
    "            elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                # Check if it's already BGR (from OpenCV)\n",
    "                # We'll assume RGB and convert to BGR\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        else:\n",
    "            raise TypeError(\"Unsupported image type. Use file path, bytes, PIL Image, or numpy array\")\n",
    "        \n",
    "        # Resize to 224x224 \n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        \n",
    "        # Convert BGR to RGB (model expects RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert to float32 (keep 0-255 range)\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Add batch dimension\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def predict(self, image):\n",
    "        # Preprocess image\n",
    "        processed_img = self.preprocess_image(image)\n",
    "        \n",
    "        # Make prediction\n",
    "        self.interpreter.set_tensor(self.input_details[0][\"index\"], processed_img)\n",
    "        self.interpreter.invoke()\n",
    "        predictions = self.interpreter.get_tensor(self.output_details[0][\"index\"])[0]\n",
    "        \n",
    "        # Get top prediction\n",
    "        predicted_idx = predictions.argmax()\n",
    "        confidence = float(predictions[predicted_idx])\n",
    "        predicted_class = self.CLASS_NAMES[predicted_idx]\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        top3_indices = predictions.argsort()[-3:][::-1]\n",
    "        top3_classes = [self.CLASS_NAMES[i] for i in top3_indices]\n",
    "        top3_confidences = [float(predictions[i]) for i in top3_indices]\n",
    "        \n",
    "        # Get confidence level\n",
    "        confidence_level = self._get_confidence_level(confidence)\n",
    "        \n",
    "        # Get plant and condition\n",
    "        plant, condition = self._parse_class_name(predicted_class)\n",
    "        \n",
    "        # Get advice based on confidence\n",
    "        advice = self._get_advice(confidence, predicted_class)\n",
    "        \n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            'success': True,\n",
    "            'predicted_class': predicted_class,\n",
    "            'friendly_name': self.FRIENDLY_NAMES.get(predicted_class, predicted_class),\n",
    "            'confidence': confidence,\n",
    "            'confidence_level': confidence_level,\n",
    "            'plant': plant,\n",
    "            'condition': condition,\n",
    "            'advice': advice,\n",
    "            'top3_predictions': [\n",
    "                {\n",
    "                    'class': top3_classes[i],\n",
    "                    'friendly_name': self.FRIENDLY_NAMES.get(top3_classes[i], top3_classes[i]),\n",
    "                    'confidence': top3_confidences[i]\n",
    "                }\n",
    "                for i in range(len(top3_classes))\n",
    "            ],\n",
    "            'all_predictions': {\n",
    "                self.CLASS_NAMES[i]: float(predictions[i]) \n",
    "                for i in range(len(self.CLASS_NAMES))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(self, images):\n",
    "        \n",
    "        results = []\n",
    "        for image in images:\n",
    "            try:\n",
    "                result = self.predict(image)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    'success': False,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        return results\n",
    "    \n",
    "    def predict_from_webcam_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Special method for webcam frames (optimized for speed)\"\"\"\n",
    "        \n",
    "        # Fast preprocessing for webcam\n",
    "        img = cv2.resize(frame, (224, 224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        self.interpreter.set_tensor(self.input_details[0][\"index\"], img)\n",
    "        self.interpreter.invoke()\n",
    "        predictions = self.interpreter.get_tensor(self.output_details[0][\"index\"])[0]\n",
    "        \n",
    "        # Get top prediction only (for speed)\n",
    "        predicted_idx = predictions.argmax()\n",
    "        confidence = float(predictions[predicted_idx])\n",
    "        predicted_class = self.CLASS_NAMES[predicted_idx]\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': predicted_class,\n",
    "            'friendly_name': self.FRIENDLY_NAMES.get(predicted_class, predicted_class),\n",
    "            'confidence': confidence,\n",
    "            'confidence_level': self._get_confidence_level(confidence)\n",
    "        }\n",
    "    \n",
    "    def _get_confidence_level(self, confidence):\n",
    "        if confidence >= 0.8:\n",
    "            return \"high\"\n",
    "        elif confidence >= 0.6:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"low\"\n",
    "    \n",
    "    def _parse_class_name(self, class_name):\n",
    "        if '___' in class_name:\n",
    "            parts = class_name.split('___')\n",
    "            plant = parts[0].replace('__', ' ').strip()\n",
    "        \n",
    "        # remove duplicate \"Tomato\"\n",
    "            if plant.startswith('Tomato Tomato'):\n",
    "                plant = plant.replace('Tomato Tomato', 'Tomato')\n",
    "        \n",
    "            condition = parts[-1].replace('_', ' ').strip()\n",
    "            return plant, condition\n",
    "        else:\n",
    "            return \"Unknown\", class_name\n",
    "    \n",
    "    def _get_advice(self, confidence, predicted_class):\n",
    "        if \"healthy\" in predicted_class.lower():\n",
    "            return \"Plant appears healthy. Continue regular monitoring.\"\n",
    "        \n",
    "        if confidence >= 0.8:\n",
    "            return \"High confidence diagnosis. Consider appropriate treatment.\"\n",
    "        elif confidence >= 0.6:\n",
    "            return \"Moderate confidence. Monitor closely and consider retesting.\"\n",
    "        else:\n",
    "            return \"Low confidence. Please verify with expert or take clearer photos.\"\n",
    "    \n",
    "    def get_class_info(self):\n",
    "        classes_info = []\n",
    "        for class_name in self.CLASS_NAMES:\n",
    "            plant, condition = self._parse_class_name(class_name)\n",
    "            classes_info.append({\n",
    "                'class_name': class_name,\n",
    "                'friendly_name': self.FRIENDLY_NAMES.get(class_name, class_name),\n",
    "                'plant': plant,\n",
    "                'condition': condition,\n",
    "                'is_healthy': 'healthy' in class_name.lower()\n",
    "            })\n",
    "        return classes_info\n",
    "\n",
    "# Helper functions for easy integration\n",
    "\n",
    "\n",
    "def create_detector(model_path=\"Models/tflite_conversion/best_model.tflite\"):\n",
    "    return PlantDiseaseDetector(model_path)\n",
    "\n",
    "def predict_image(image, model_path=None):\n",
    "  \n",
    "    detector = PlantDiseaseDetector(model_path) if model_path else create_detector()\n",
    "    return detector.predict(image)\n",
    "\n",
    "def predict_webcam_frame(frame, model_path=None):\n",
    "   \n",
    "    detector = PlantDiseaseDetector(model_path) if model_path else create_detector()\n",
    "    return detector.predict_from_webcam_frame(frame)\n",
    "\n",
    "\n",
    "# Example usage for gui \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Basic usage\n",
    "    print(\"Example 1: Basic usage\")\n",
    "    detector = PlantDiseaseDetector()\n",
    "    \n",
    "    # From file path\n",
    "    result = detector.predict(\"path/to/your/image.jpg\")\n",
    "    print(f\"Prediction: {result['friendly_name']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"Advice: {result['advice']}\")\n",
    "    \n",
    "    # Example 2: For Streamlit integration\n",
    "    print(\"\\nExample 2: Streamlit-ready usage\")\n",
    "    \n",
    "    # In Streamlit, gui would use:\n",
    "    \"\"\"\n",
    "    import streamlit as st\n",
    "    from plant_detector import predict_image\n",
    "    from PIL import Image\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"Upload plant image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    \n",
    "    if uploaded_file:\n",
    "        # Convert to PIL Image\n",
    "        image = Image.open(uploaded_file)\n",
    "        \n",
    "        # Get prediction\n",
    "        result = predict_image(image)\n",
    "        \n",
    "        # Display results\n",
    "        st.image(image, caption=\"Uploaded Image\", width=300)\n",
    "        st.success(f\"**Diagnosis:** {result['friendly_name']}\")\n",
    "        st.metric(\"Confidence\", f\"{result['confidence']:.2%}\")\n",
    "        st.info(f\"**Advice:** {result['advice']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example 3: Webcam in Streamlit\n",
    "    print(\"\\nExample 3: Webcam usage\")\n",
    "    \"\"\"\n",
    "    # In Streamlit with streamlit-webrtc:\n",
    "    from streamlit_webrtc import webrtc_streamer\n",
    "    from plant_detector import predict_webcam_frame\n",
    "    \n",
    "    def video_frame_callback(frame):\n",
    "        img = frame.to_ndarray(format=\"bgr24\")\n",
    "        result = predict_webcam_frame(img)\n",
    "        \n",
    "        # Add text to frame\n",
    "        cv2.putText(img, result['friendly_name'], (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    webrtc_streamer(key=\"plant-detector\", video_frame_callback=video_frame_callback)\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
